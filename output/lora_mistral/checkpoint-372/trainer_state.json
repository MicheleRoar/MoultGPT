{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 372,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08080808080808081,
      "grad_norm": 1.7220187187194824,
      "learning_rate": 0.00019516129032258066,
      "loss": 2.0813,
      "step": 10
    },
    {
      "epoch": 0.16161616161616163,
      "grad_norm": 2.9302937984466553,
      "learning_rate": 0.00018978494623655916,
      "loss": 1.7605,
      "step": 20
    },
    {
      "epoch": 0.24242424242424243,
      "grad_norm": 4.695734024047852,
      "learning_rate": 0.00018440860215053763,
      "loss": 1.4629,
      "step": 30
    },
    {
      "epoch": 0.32323232323232326,
      "grad_norm": 3.784644365310669,
      "learning_rate": 0.00017903225806451613,
      "loss": 1.1689,
      "step": 40
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 4.734827041625977,
      "learning_rate": 0.00017365591397849463,
      "loss": 0.871,
      "step": 50
    },
    {
      "epoch": 0.48484848484848486,
      "grad_norm": 6.1395487785339355,
      "learning_rate": 0.00016827956989247313,
      "loss": 0.6636,
      "step": 60
    },
    {
      "epoch": 0.5656565656565656,
      "grad_norm": 4.0046706199646,
      "learning_rate": 0.00016290322580645163,
      "loss": 0.4666,
      "step": 70
    },
    {
      "epoch": 0.6464646464646465,
      "grad_norm": 4.250384330749512,
      "learning_rate": 0.0001575268817204301,
      "loss": 0.325,
      "step": 80
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 6.161840915679932,
      "learning_rate": 0.0001521505376344086,
      "loss": 0.1724,
      "step": 90
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 2.758427858352661,
      "learning_rate": 0.0001467741935483871,
      "loss": 0.1383,
      "step": 100
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 2.758458375930786,
      "learning_rate": 0.0001413978494623656,
      "loss": 0.1201,
      "step": 110
    },
    {
      "epoch": 0.9696969696969697,
      "grad_norm": 3.0757811069488525,
      "learning_rate": 0.00013602150537634408,
      "loss": 0.0921,
      "step": 120
    },
    {
      "epoch": 1.0484848484848486,
      "grad_norm": 2.5633373260498047,
      "learning_rate": 0.00013064516129032258,
      "loss": 0.0856,
      "step": 130
    },
    {
      "epoch": 1.1292929292929292,
      "grad_norm": 3.358475923538208,
      "learning_rate": 0.00012526881720430108,
      "loss": 0.0738,
      "step": 140
    },
    {
      "epoch": 1.2101010101010101,
      "grad_norm": 1.8388675451278687,
      "learning_rate": 0.00011989247311827958,
      "loss": 0.0648,
      "step": 150
    },
    {
      "epoch": 1.290909090909091,
      "grad_norm": 1.3098292350769043,
      "learning_rate": 0.00011451612903225808,
      "loss": 0.0611,
      "step": 160
    },
    {
      "epoch": 1.3717171717171717,
      "grad_norm": 1.248572826385498,
      "learning_rate": 0.00010913978494623656,
      "loss": 0.0574,
      "step": 170
    },
    {
      "epoch": 1.4525252525252526,
      "grad_norm": 1.332871913909912,
      "learning_rate": 0.00010376344086021505,
      "loss": 0.0625,
      "step": 180
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 1.6828534603118896,
      "learning_rate": 9.838709677419355e-05,
      "loss": 0.0429,
      "step": 190
    },
    {
      "epoch": 1.614141414141414,
      "grad_norm": 1.2287184000015259,
      "learning_rate": 9.301075268817204e-05,
      "loss": 0.0471,
      "step": 200
    },
    {
      "epoch": 1.694949494949495,
      "grad_norm": 0.9943934082984924,
      "learning_rate": 8.763440860215054e-05,
      "loss": 0.0498,
      "step": 210
    },
    {
      "epoch": 1.7757575757575759,
      "grad_norm": 1.1062928438186646,
      "learning_rate": 8.225806451612904e-05,
      "loss": 0.0508,
      "step": 220
    },
    {
      "epoch": 1.8565656565656565,
      "grad_norm": 0.914375364780426,
      "learning_rate": 7.688172043010752e-05,
      "loss": 0.0508,
      "step": 230
    },
    {
      "epoch": 1.9373737373737374,
      "grad_norm": 0.6778721213340759,
      "learning_rate": 7.150537634408602e-05,
      "loss": 0.0473,
      "step": 240
    },
    {
      "epoch": 2.0161616161616163,
      "grad_norm": 0.5135976672172546,
      "learning_rate": 6.612903225806452e-05,
      "loss": 0.0441,
      "step": 250
    },
    {
      "epoch": 2.096969696969697,
      "grad_norm": 0.49015581607818604,
      "learning_rate": 6.0752688172043016e-05,
      "loss": 0.0317,
      "step": 260
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 0.6196153163909912,
      "learning_rate": 5.53763440860215e-05,
      "loss": 0.036,
      "step": 270
    },
    {
      "epoch": 2.2585858585858585,
      "grad_norm": 0.46605461835861206,
      "learning_rate": 5e-05,
      "loss": 0.0428,
      "step": 280
    },
    {
      "epoch": 2.3393939393939394,
      "grad_norm": 0.42501768469810486,
      "learning_rate": 4.4623655913978496e-05,
      "loss": 0.034,
      "step": 290
    },
    {
      "epoch": 2.4202020202020202,
      "grad_norm": 0.7897105813026428,
      "learning_rate": 3.924731182795699e-05,
      "loss": 0.032,
      "step": 300
    },
    {
      "epoch": 2.501010101010101,
      "grad_norm": 0.5469017028808594,
      "learning_rate": 3.387096774193548e-05,
      "loss": 0.034,
      "step": 310
    },
    {
      "epoch": 2.581818181818182,
      "grad_norm": 0.5139340162277222,
      "learning_rate": 2.8494623655913982e-05,
      "loss": 0.0394,
      "step": 320
    },
    {
      "epoch": 2.6626262626262625,
      "grad_norm": 0.8016729950904846,
      "learning_rate": 2.3118279569892472e-05,
      "loss": 0.0351,
      "step": 330
    },
    {
      "epoch": 2.7434343434343433,
      "grad_norm": 0.5391980409622192,
      "learning_rate": 1.774193548387097e-05,
      "loss": 0.035,
      "step": 340
    },
    {
      "epoch": 2.824242424242424,
      "grad_norm": 0.37245652079582214,
      "learning_rate": 1.2365591397849464e-05,
      "loss": 0.0383,
      "step": 350
    },
    {
      "epoch": 2.905050505050505,
      "grad_norm": 0.26219117641448975,
      "learning_rate": 6.989247311827957e-06,
      "loss": 0.0384,
      "step": 360
    },
    {
      "epoch": 2.985858585858586,
      "grad_norm": 0.6402014493942261,
      "learning_rate": 1.6129032258064516e-06,
      "loss": 0.034,
      "step": 370
    }
  ],
  "logging_steps": 10,
  "max_steps": 372,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2987263801622528e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
